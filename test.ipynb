{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c32ad4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'engine': 'google_scholar',\n",
    "    'q': 'law legal',\n",
    "    # 'api_key': self.serpapi_key,\n",
    "    'api_key' : \"3611eaea5638a59ec95b6329077ddd9c8a71ece3\",\n",
    "    'num': 10\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94bd0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808051de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SearchResult:\n",
    "    title: str\n",
    "    url: str\n",
    "    snippet: str\n",
    "    source: str\n",
    "    relevance_score: float\n",
    "    publication_date: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "        \"What are the latest developments in AI liability law?\",\n",
    "        \"Find research papers on Fourth Amendment and digital privacy\",\n",
    "        \"Contract law cases involving force majeure during COVID-19\",\n",
    "        \"Environmental law and carbon credit regulations\",\n",
    "        \"Criminal procedure and Miranda rights exceptions\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "140901dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_relevance(self, text: str, context) -> float:\n",
    "    \"\"\"Calculate relevance score based on keyword matching and context\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    score = 0.0\n",
    "    \n",
    "    # Keyword matching\n",
    "    for keyword in context.keywords:\n",
    "        if keyword.lower() in text_lower:\n",
    "            score += 0.1\n",
    "    \n",
    "    # Legal domain matching\n",
    "    domain_terms = self.legal_domains.get(context.legal_domain, [])\n",
    "    for term in domain_terms:\n",
    "        if term in text_lower:\n",
    "            score += 0.15\n",
    "    \n",
    "    # Boost for academic terms\n",
    "    academic_terms = ['journal', 'review', 'law review', 'university', 'court', 'case']\n",
    "    for term in academic_terms:\n",
    "        if term in text_lower:\n",
    "            score += 0.1\n",
    "    \n",
    "    return min(score, 1.0)  # Cap at 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8863be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://serpapi.com/search', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b96b7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [401]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9bfc006",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://google.serper.dev', params=params)\n",
    "data = response.json()\n",
    "results = []\n",
    "    \n",
    "for item in data.get('organic_results', []):\n",
    "    print(1)\n",
    "    results.append(SearchResult(\n",
    "        title=item.get('title', ''),\n",
    "        url=item.get('link', ''),\n",
    "        snippet=item.get('snippet', ''),\n",
    "        source='Google Scholar',\n",
    "        relevance_score=_calculate_relevance(item.get('title', '') + ' ' + item.get('snippet', ''), \"What are the latest developments in AI liability law?\"),\n",
    "        publication_date=item.get('publication_info', {}).get('summary', '')\n",
    "    ))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9596bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06de0219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì Choose search type:\n",
      "1. Comprehensive authoritative search demo\n",
      "2. Search specific sources (ResearchGate, SSRN, etc.)\n",
      "3. Academic databases only\n",
      "4. Law reviews only\n",
      "üîç Searching 'pink tribunal' across specific sources:\n",
      "============================================================\n",
      "\n",
      "üìö Searching RESEARCHGATE:\n",
      "‚ùå Search Error: HTTP 403\n",
      "\n",
      "üìö Searching SSRN:\n",
      "‚ùå Search Error: HTTP 403\n",
      "\n",
      "üìö Searching JSTOR:\n",
      "‚ùå Search Error: HTTP 403\n",
      "\n",
      "üìö Searching HARVARD LAW:\n",
      "‚ùå Search Error: HTTP 403\n",
      "\n",
      "üìö Searching OXFORD:\n",
      "‚ùå Search Error: HTTP 403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Dict, List, Optional\n",
    "import time\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "class AuthoritativeLegalSearch:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize Serper API client for authoritative legal research sources\n",
    "        \n",
    "        Args:\n",
    "            api_key: Your Serper API key from https://serper.dev/\n",
    "        \"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://google.serper.dev\"\n",
    "        \n",
    "        # Authoritative legal and academic sources\n",
    "        self.legal_sources = {\n",
    "            'researchgate': 'site:researchgate.net',\n",
    "            'ssrn': 'site:ssrn.com OR site:papers.ssrn.com',\n",
    "            'jstor': 'site:jstor.org',\n",
    "            'heinonline': 'site:heinonline.org',\n",
    "            'westlaw': 'site:westlaw.com OR site:next.westlaw.com',\n",
    "            'lexisnexis': 'site:lexisnexis.com',\n",
    "            'cambridge': 'site:cambridge.org',\n",
    "            'oxford': 'site:academic.oup.com OR site:oxfordlawtrove.com',\n",
    "            'taylor_francis': 'site:tandfonline.com',\n",
    "            'springer': 'site:springer.com OR site:link.springer.com',\n",
    "            'wiley': 'site:onlinelibrary.wiley.com',\n",
    "            'sage': 'site:journals.sagepub.com',\n",
    "            'harvard_law': 'site:harvardlawreview.org',\n",
    "            'yale_law': 'site:yalelawjournal.org',\n",
    "            'stanford_law': 'site:stanfordlawreview.org',\n",
    "            'columbia_law': 'site:columbialawreview.org',\n",
    "            'chicago_law': 'site:lawreview.uchicago.edu',\n",
    "            'nyu_law': 'site:nyulawreview.org',\n",
    "            'penn_law': 'site:pennlawreview.com',\n",
    "            'georgetown_law': 'site:georgetownlawjournal.org',\n",
    "            'cornell_law': 'site:lawschool.cornell.edu',\n",
    "            'bepress': 'site:bepress.com',\n",
    "            'elsevier': 'site:sciencedirect.com',\n",
    "            'proquest': 'site:proquest.com',\n",
    "            'hathitrust': 'site:hathitrust.org',\n",
    "            'google_scholar': 'site:scholar.google.com'\n",
    "        }\n",
    "        \n",
    "        # Legal research keywords for enhanced queries\n",
    "        self.legal_keywords = [\n",
    "            '\"law review\"', '\"legal journal\"', '\"legal analysis\"',\n",
    "            '\"case law\"', '\"legal research\"', '\"jurisprudence\"',\n",
    "            '\"legal scholarship\"', '\"court decision\"', '\"legal doctrine\"',\n",
    "            '\"statutory interpretation\"', '\"constitutional law\"',\n",
    "            '\"legal precedent\"', '\"judicial opinion\"'\n",
    "        ]\n",
    "    \n",
    "    def search_all_sources(self, query: str, num_results: int = 20) -> Dict:\n",
    "        \"\"\"\n",
    "        Search across all authoritative legal sources\n",
    "        \n",
    "        Args:\n",
    "            query: Legal research query\n",
    "            num_results: Number of results per source type\n",
    "        \n",
    "        Returns:\n",
    "            Combined results from all sources\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create comprehensive site search query\n",
    "        site_queries = ' OR '.join(self.legal_sources.values())\n",
    "        legal_terms = ' OR '.join(self.legal_keywords[:5])  # Use top 5 legal keywords\n",
    "        \n",
    "        enhanced_query = f'({query}) AND ({site_queries}) AND ({legal_terms})'\n",
    "        \n",
    "        headers = {\n",
    "            'X-API-KEY': self.api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            'q': enhanced_query,\n",
    "            'num': num_results,\n",
    "            'gl': 'us',\n",
    "            'hl': 'en'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(f\"{self.base_url}/search\", \n",
    "                                   headers=headers, \n",
    "                                   data=json.dumps(payload))\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return {\"error\": f\"HTTP {response.status_code}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def search_specific_source(self, query: str, source: str, num_results: int = 10) -> Dict:\n",
    "        \"\"\"\n",
    "        Search a specific authoritative source\n",
    "        \n",
    "        Args:\n",
    "            query: Legal research query\n",
    "            source: Source key (e.g., 'researchgate', 'ssrn', 'jstor')\n",
    "            num_results: Number of results to return\n",
    "        \n",
    "        Returns:\n",
    "            Search results from specific source\n",
    "        \"\"\"\n",
    "        \n",
    "        if source not in self.legal_sources:\n",
    "            return {\"error\": f\"Unknown source: {source}. Available: {list(self.legal_sources.keys())}\"}\n",
    "        \n",
    "        site_filter = self.legal_sources[source]\n",
    "        legal_terms = ' OR '.join(self.legal_keywords[:3])\n",
    "        \n",
    "        enhanced_query = f'({query}) AND ({site_filter}) AND ({legal_terms})'\n",
    "        \n",
    "        headers = {\n",
    "            'X-API-KEY': self.api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            'q': enhanced_query,\n",
    "            'num': num_results,\n",
    "            'gl': 'us',\n",
    "            'hl': 'en'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(f\"{self.base_url}/search\", \n",
    "                                   headers=headers, \n",
    "                                   data=json.dumps(payload))\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return {\"error\": f\"HTTP {response.status_code}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def search_academic_databases(self, query: str, num_results: int = 15) -> Dict:\n",
    "        \"\"\"\n",
    "        Search specifically academic databases (JSTOR, SSRN, ResearchGate, etc.)\n",
    "        \n",
    "        Args:\n",
    "            query: Academic legal research query\n",
    "            num_results: Number of results to return\n",
    "        \n",
    "        Returns:\n",
    "            Results from academic databases only\n",
    "        \"\"\"\n",
    "        \n",
    "        academic_sources = [\n",
    "            self.legal_sources['researchgate'],\n",
    "            self.legal_sources['ssrn'],\n",
    "            self.legal_sources['jstor'],\n",
    "            self.legal_sources['springer'],\n",
    "            self.legal_sources['cambridge'],\n",
    "            self.legal_sources['oxford'],\n",
    "            self.legal_sources['taylor_francis'],\n",
    "            self.legal_sources['wiley'],\n",
    "            self.legal_sources['sage'],\n",
    "            self.legal_sources['elsevier'],\n",
    "            self.legal_sources['bepress']\n",
    "        ]\n",
    "        \n",
    "        site_queries = ' OR '.join(academic_sources)\n",
    "        academic_terms = '\"peer reviewed\" OR \"academic journal\" OR \"research paper\" OR \"scholarly article\"'\n",
    "        \n",
    "        enhanced_query = f'({query}) AND ({site_queries}) AND ({academic_terms})'\n",
    "        \n",
    "        headers = {\n",
    "            'X-API-KEY': self.api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            'q': enhanced_query,\n",
    "            'num': num_results,\n",
    "            'gl': 'us',\n",
    "            'hl': 'en'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(f\"{self.base_url}/search\", \n",
    "                                   headers=headers, \n",
    "                                   data=json.dumps(payload))\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return {\"error\": f\"HTTP {response.status_code}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def search_law_reviews(self, query: str, num_results: int = 15) -> Dict:\n",
    "        \"\"\"\n",
    "        Search top law reviews and journals\n",
    "        \n",
    "        Args:\n",
    "            query: Legal research query\n",
    "            num_results: Number of results to return\n",
    "        \n",
    "        Returns:\n",
    "            Results from prestigious law reviews\n",
    "        \"\"\"\n",
    "        \n",
    "        law_review_sources = [\n",
    "            self.legal_sources['harvard_law'],\n",
    "            self.legal_sources['yale_law'],\n",
    "            self.legal_sources['stanford_law'],\n",
    "            self.legal_sources['columbia_law'],\n",
    "            self.legal_sources['chicago_law'],\n",
    "            self.legal_sources['nyu_law'],\n",
    "            self.legal_sources['penn_law'],\n",
    "            self.legal_sources['georgetown_law'],\n",
    "            self.legal_sources['cornell_law']\n",
    "        ]\n",
    "        \n",
    "        site_queries = ' OR '.join(law_review_sources)\n",
    "        law_review_terms = '\"law review\" OR \"legal journal\" OR \"law quarterly\" OR \"law forum\"'\n",
    "        \n",
    "        enhanced_query = f'({query}) AND ({site_queries}) AND ({law_review_terms})'\n",
    "        \n",
    "        headers = {\n",
    "            'X-API-KEY': self.api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            'q': enhanced_query,\n",
    "            'num': num_results,\n",
    "            'gl': 'us',\n",
    "            'hl': 'en'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(f\"{self.base_url}/search\", \n",
    "                                   headers=headers, \n",
    "                                   data=json.dumps(payload))\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return {\"error\": f\"HTTP {response.status_code}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def search_google_scholar_legal(self, query: str, num_results: int = 10) -> Dict:\n",
    "        \"\"\"\n",
    "        Search Google Scholar specifically for legal academic papers\n",
    "        \n",
    "        Args:\n",
    "            query: Academic legal search query\n",
    "            num_results: Number of results to return\n",
    "        \n",
    "        Returns:\n",
    "            Google Scholar results for legal research\n",
    "        \"\"\"\n",
    "        \n",
    "        # Enhanced query for legal academic papers\n",
    "        enhanced_query = f'{query} law legal \"cited by\" academic research'\n",
    "        \n",
    "        headers = {\n",
    "            'X-API-KEY': self.api_key,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            'q': enhanced_query,\n",
    "            'num': num_results\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(f\"{self.base_url}/scholar\", \n",
    "                                   headers=headers, \n",
    "                                   data=json.dumps(payload))\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            else:\n",
    "                return {\"error\": f\"HTTP {response.status_code}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "def identify_source(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Identify the source/platform from URL\n",
    "    \n",
    "    Args:\n",
    "        url: The URL to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Source name\n",
    "    \"\"\"\n",
    "    \n",
    "    source_mapping = {\n",
    "        'researchgate.net': 'üî¨ ResearchGate',\n",
    "        'ssrn.com': 'üìö SSRN',\n",
    "        'papers.ssrn.com': 'üìö SSRN Papers',\n",
    "        'jstor.org': 'üìñ JSTOR',\n",
    "        'heinonline.org': '‚öñÔ∏è HeinOnline',\n",
    "        'westlaw.com': '‚öñÔ∏è Westlaw',\n",
    "        'lexisnexis.com': 'üìë LexisNexis',\n",
    "        'cambridge.org': 'üéì Cambridge',\n",
    "        'academic.oup.com': 'üéì Oxford Academic',\n",
    "        'oxfordlawtrove.com': '‚öñÔ∏è Oxford Law Trove',\n",
    "        'tandfonline.com': 'üìö Taylor & Francis',\n",
    "        'springer.com': 'üìö Springer',\n",
    "        'link.springer.com': 'üìö Springer Link',\n",
    "        'onlinelibrary.wiley.com': 'üìö Wiley Online',\n",
    "        'journals.sagepub.com': 'üìö SAGE Journals',\n",
    "        'harvardlawreview.org': 'üèõÔ∏è Harvard Law Review',\n",
    "        'yalelawjournal.org': 'üèõÔ∏è Yale Law Journal',\n",
    "        'stanfordlawreview.org': 'üèõÔ∏è Stanford Law Review',\n",
    "        'columbialawreview.org': 'üèõÔ∏è Columbia Law Review',\n",
    "        'lawreview.uchicago.edu': 'üèõÔ∏è Chicago Law Review',\n",
    "        'nyulawreview.org': 'üèõÔ∏è NYU Law Review',\n",
    "        'sciencedirect.com': 'üî¨ ScienceDirect',\n",
    "        'bepress.com': 'üìö bepress',\n",
    "        'proquest.com': 'üìö ProQuest'\n",
    "    }\n",
    "    \n",
    "    for domain, source in source_mapping.items():\n",
    "        if domain in url.lower():\n",
    "            return source\n",
    "    \n",
    "    return 'üåê Academic Source'\n",
    "\n",
    "def format_authoritative_results(results: Dict, search_type: str = \"Authoritative Sources\") -> str:\n",
    "    \"\"\"\n",
    "    Format search results with source identification and academic metrics\n",
    "    \n",
    "    Args:\n",
    "        results: Search results from Serper API\n",
    "        search_type: Type of search performed\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string of results with source attribution\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"error\" in results:\n",
    "        return f\"‚ùå Search Error: {results['error']}\"\n",
    "    \n",
    "    output = f\"\\nüìö {search_type.upper()}\\n\"\n",
    "    output += \"=\" * 70 + \"\\n\"\n",
    "    \n",
    "    # Handle different result structures\n",
    "    if search_type.lower() == \"scholar\":\n",
    "        organic_results = results.get('organic', [])\n",
    "    else:\n",
    "        organic_results = results.get('organic', [])\n",
    "    \n",
    "    if not organic_results:\n",
    "        return f\"‚ùå No authoritative sources found for {search_type} search.\"\n",
    "    \n",
    "    for i, result in enumerate(organic_results, 1):\n",
    "        title = result.get('title', 'No Title')\n",
    "        url = result.get('link', 'No URL')\n",
    "        source = identify_source(url)\n",
    "        \n",
    "        output += f\"\\n{i}. {title}\\n\"\n",
    "        output += f\"   üìç Source: {source}\\n\"\n",
    "        output += f\"   üîó URL: {url}\\n\"\n",
    "        \n",
    "        # Handle different snippet fields\n",
    "        snippet = result.get('snippet') or result.get('description') or 'No description available'\n",
    "        output += f\"   üìÑ Abstract: {snippet}\\n\"\n",
    "        \n",
    "        # Scholar-specific academic metrics\n",
    "        if search_type.lower() == \"scholar\":\n",
    "            if 'publication_info' in result:\n",
    "                pub_info = result['publication_info']\n",
    "                summary = pub_info.get('summary', '')\n",
    "                if summary:\n",
    "                    output += f\"   üìÖ Publication: {summary}\\n\"\n",
    "            \n",
    "            if 'cited_by' in result:\n",
    "                citations = result['cited_by']\n",
    "                total_citations = citations.get('total', 0)\n",
    "                citations_link = citations.get('link', '')\n",
    "                output += f\"   üìä Citations: {total_citations}\\n\"\n",
    "                if citations_link:\n",
    "                    output += f\"   üîç Citation Link: {citations_link}\\n\"\n",
    "            \n",
    "            if 'related_pages' in result:\n",
    "                related = result['related_pages']\n",
    "                if 'link' in related:\n",
    "                    output += f\"   üîó Related Articles: {related['link']}\\n\"\n",
    "        \n",
    "        # Check for PDF availability\n",
    "        if 'pdf' in url.lower() or 'filetype:pdf' in str(result):\n",
    "            output += f\"   üìÑ Format: PDF Available\\n\"\n",
    "        \n",
    "        # Check for DOI or academic identifiers\n",
    "        if 'doi.org' in url or 'doi:' in snippet.lower():\n",
    "            output += f\"   üÜî DOI: Available\\n\"\n",
    "        \n",
    "        output += \"   \" + \"-\" * 60 + \"\\n\"\n",
    "    \n",
    "    # Search metadata\n",
    "    if 'searchInformation' in results:\n",
    "        search_info = results['searchInformation']\n",
    "        total_results = search_info.get('totalResults', 'Unknown')\n",
    "        search_time = search_info.get('searchTime', 'Unknown')\n",
    "        output += f\"\\nüìä Total Authoritative Results: {total_results}\"\n",
    "        output += f\" | ‚è±Ô∏è Search Time: {search_time}s\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def demo_authoritative_searches():\n",
    "    \"\"\"\n",
    "    Demo function showing searches across authoritative legal sources\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize with your Serper API key\n",
    "    API_KEY = \"your-serper-api-key-here\"\n",
    "    \n",
    "    searcher = AuthoritativeLegalSearch(API_KEY)\n",
    "    \n",
    "    # Sample legal research queries\n",
    "    test_queries = [\n",
    "        \"artificial intelligence liability tort law\",\n",
    "        \"constitutional privacy digital surveillance\",\n",
    "        \"environmental law climate change litigation\",\n",
    "        \"corporate governance fiduciary duty\",\n",
    "        \"intellectual property fair use doctrine\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üéì AUTHORITATIVE LEGAL RESEARCH SEARCH DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nüîç Research Query: '{query}'\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # 1. Search all authoritative sources\n",
    "        print(\"\\n1Ô∏è‚É£ ALL AUTHORITATIVE SOURCES:\")\n",
    "        all_results = searcher.search_all_sources(query, num_results=8)\n",
    "        print(format_authoritative_results(all_results, \"All Authoritative Sources\"))\n",
    "        \n",
    "        # 2. Academic databases only\n",
    "        print(\"\\n2Ô∏è‚É£ ACADEMIC DATABASES (JSTOR, SSRN, ResearchGate, etc.):\")\n",
    "        academic_results = searcher.search_academic_databases(query, num_results=6)\n",
    "        print(format_authoritative_results(academic_results, \"Academic Databases\"))\n",
    "        \n",
    "        # 3. Top law reviews\n",
    "        print(\"\\n3Ô∏è‚É£ PRESTIGIOUS LAW REVIEWS:\")\n",
    "        law_review_results = searcher.search_law_reviews(query, num_results=5)\n",
    "        print(format_authoritative_results(law_review_results, \"Law Reviews\"))\n",
    "        \n",
    "        # 4. Google Scholar for citations\n",
    "        print(\"\\n4Ô∏è‚É£ GOOGLE SCHOLAR (WITH CITATIONS):\")\n",
    "        scholar_results = searcher.search_google_scholar_legal(query, num_results=5)\n",
    "        print(format_authoritative_results(scholar_results, \"Scholar\"))\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        time.sleep(3)  # Rate limiting\n",
    "\n",
    "def search_specific_source_demo():\n",
    "    \"\"\"\n",
    "    Demo searching specific authoritative sources\n",
    "    \"\"\"\n",
    "    \n",
    "    API_KEY = \"your-serper-api-key-here\"\n",
    "    searcher = AuthoritativeLegalSearch(API_KEY)\n",
    "    \n",
    "    query = \"pink tribunal\"\n",
    "    \n",
    "    # Available sources\n",
    "    sources = ['researchgate', 'ssrn', 'jstor', 'harvard_law', 'oxford']\n",
    "    \n",
    "    print(f\"üîç Searching '{query}' across specific sources:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for source in sources:\n",
    "        print(f\"\\nüìö Searching {source.upper().replace('_', ' ')}:\")\n",
    "        results = searcher.search_specific_source(query, source, num_results=5)\n",
    "        print(format_authoritative_results(results, f\"{source} Results\"))\n",
    "        time.sleep(2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéì Choose search type:\")\n",
    "    print(\"1. Comprehensive authoritative search demo\")\n",
    "    print(\"2. Search specific sources (ResearchGate, SSRN, etc.)\")\n",
    "    print(\"3. Academic databases only\")\n",
    "    print(\"4. Law reviews only\")\n",
    "    \n",
    "    choice = input(\"\\nEnter choice (1-4): \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        demo_authoritative_searches()\n",
    "    elif choice == \"2\":\n",
    "        search_specific_source_demo()\n",
    "    elif choice == \"3\":\n",
    "        API_KEY = \"your-serper-api-key-here\"\n",
    "        searcher = AuthoritativeLegalSearch(API_KEY)\n",
    "        query = input(\"Enter your legal research query: \")\n",
    "        results = searcher.search_academic_databases(query, 10)\n",
    "        print(format_authoritative_results(results, \"Academic Databases\"))\n",
    "    elif choice == \"4\":\n",
    "        API_KEY = \"your-serper-api-key-here\"\n",
    "        searcher = AuthoritativeLegalSearch(API_KEY)\n",
    "        query = input(\"Enter your legal research query: \")\n",
    "        results = searcher.search_law_reviews(query, 10)\n",
    "        print(format_authoritative_results(results, \"Law Reviews\"))\n",
    "    else:\n",
    "        print(\"Running comprehensive demo...\")\n",
    "        demo_authoritative_searches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8336aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
